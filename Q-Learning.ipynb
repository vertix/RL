{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.contrib.layers\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WeightedExperienceBuffer(object):\n",
    "    def __init__(self, alpha, beta, max_weight, buffer_size=1<<16):\n",
    "        self.ss, self.aa, self.rr, self.ss1, self.gg = None, None, None, None, None\n",
    "        self.buffer_size = buffer_size\n",
    "        self.inserted = 0\n",
    "        self.tree_size = buffer_size << 1\n",
    "        # root is 1\n",
    "        self.weight_sums = np.zeros(self.tree_size)\n",
    "        self.weight_min = np.ones(self.tree_size) * (max_weight ** alpha)\n",
    "        self.max_weight = max_weight\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def update_up(self, index):\n",
    "        self.weight_sums[index] = self.weight_sums[index << 1] + self.weight_sums[(index << 1) + 1]\n",
    "        self.weight_min[index] = min(self.weight_min[index << 1], self.weight_min[(index << 1) + 1])\n",
    "        if index > 1:\n",
    "            self.update_up(index >> 1)\n",
    "\n",
    "    def index_in_tree(self, buffer_index):\n",
    "        return buffer_index + self.buffer_size\n",
    "\n",
    "    def index_in_buffer(self, tree_index):\n",
    "        return tree_index - self.buffer_size\n",
    "\n",
    "    def tree_update(self, buffer_index, new_weight):\n",
    "        index = self.index_in_tree(buffer_index)\n",
    "        new_weight = min(new_weight + 0.01, self.max_weight) ** self.alpha\n",
    "\n",
    "        self.weight_sums[index] = new_weight\n",
    "        self.weight_min[index] = new_weight\n",
    "        self.update_up(index >> 1)\n",
    "\n",
    "    def add(self, s, a, r, s1, gamma, weight):\n",
    "        if self.ss is None:\n",
    "            # Initialize\n",
    "            state_size = s.shape[1]\n",
    "            self.ss = np.zeros((state_size, self.buffer_size), dtype=np.float32)\n",
    "            self.aa = np.zeros(self.buffer_size, dtype=np.int16)\n",
    "            self.ss1 = np.zeros((state_size, self.buffer_size), dtype=np.float32)\n",
    "            self.rr = np.zeros(self.buffer_size, dtype=np.float32)\n",
    "            self.gg = np.zeros(self.buffer_size, dtype=np.float32)\n",
    "\n",
    "        indexes = []\n",
    "        for _ in a:\n",
    "            cur_index = self.inserted % self.buffer_size\n",
    "            self.inserted += 1\n",
    "            indexes.append(cur_index)\n",
    "\n",
    "        self.ss[:, indexes] = s.transpose()\n",
    "        self.aa[indexes] = a\n",
    "        self.rr[indexes] = r\n",
    "        self.ss1[:, indexes] = s1.transpose()\n",
    "        self.gg[indexes] = gamma\n",
    "\n",
    "        for idx in indexes:\n",
    "            self.tree_update(idx, weight)\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return None if self.ss is None else self.ss.shape[0]\n",
    "\n",
    "    def find_sum(self, node, sum):\n",
    "        if node >= self.buffer_size:\n",
    "            return self.index_in_buffer(node)\n",
    "        left = node << 1\n",
    "        left_sum = self.weight_sums[left]\n",
    "        if sum < left_sum:\n",
    "            return self.find_sum(left, sum)\n",
    "        else:\n",
    "            return self.find_sum(left + 1, sum - left_sum)\n",
    "\n",
    "    def sample_indexes(self, size):\n",
    "        total_weight = self.weight_sums[1]\n",
    "        indexes = np.zeros(size, dtype=np.int32)\n",
    "        for i in xrange(size):\n",
    "            search = np.random.random() * total_weight\n",
    "            indexes[i] = self.find_sum(1, search)\n",
    "        return indexes\n",
    "\n",
    "    def sample(self, size):\n",
    "        if size > self.inserted:\n",
    "            return None, None, None, None, None, None, None\n",
    "\n",
    "        indexes = self.sample_indexes(size)\n",
    "        max_w = (self.weight_min[1] / self.weight_sums[1]) ** -self.beta\n",
    "        w = (self.weight_sums[self.index_in_tree(indexes)] / self.weight_sums[1]) ** -self.beta\n",
    "\n",
    "        return (indexes,\n",
    "                np.transpose(self.ss[:, indexes]), self.aa[indexes], self.rr[indexes],\n",
    "                np.transpose(self.ss1[:, indexes]), self.gg[indexes],\n",
    "                w / max_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def HuberLoss(tensor, boundary):\n",
    "    abs_x = tf.abs(tensor)\n",
    "    delta = boundary\n",
    "    quad = tf.minimum(abs_x, delta)\n",
    "    lin = (abs_x - quad)\n",
    "    return 0.5 * quad ** 2 + delta * lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BaseLearner(object):\n",
    "    def __init__(self, options):\n",
    "        self.options = options\n",
    "\n",
    "    def Vars(self):\n",
    "        return tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "\n",
    "    def Init(self, sess, run_index):\n",
    "        self.run_index = run_index\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        self.writer = tf.summary.FileWriter(\n",
    "            '/Users/vertix/Documents/tensorflow_logs/%s'  % self.run_index\n",
    "        )\n",
    "        self.saver = tf.train.Saver(self.Vars())\n",
    "        self.cur_step = 0\n",
    "        self.writer.add_graph(tf.get_default_graph())\n",
    "        self.last_start = time.time()\n",
    "\n",
    "    def Optimize(self, loss):\n",
    "        \"\"\"Returns optimization operation\"\"\"\n",
    "        self.global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "        self.optimizer = tf.train.AdamOptimizer(self.options['learning_rate'])\n",
    "        variables = self.Vars()\n",
    "        grads = self.optimizer.compute_gradients(loss, variables)\n",
    "        if 'clip_grad' in self.options:\n",
    "            gg = [g for g, _ in grads]\n",
    "            vv = [v for _, v in grads]\n",
    "            global_norm = tf.global_norm(gg)\n",
    "            tf.summary.scalar('Scalars/Grad_norm', global_norm)\n",
    "            grads = zip(tf.clip_by_global_norm(gg, self.options['clip_grad'], global_norm)[0], vv)\n",
    "\n",
    "        for grad, v in grads:\n",
    "            if grad is not None:\n",
    "                tf.summary.histogram('{}/grad'.format(v.name), grad)\n",
    "            tf.summary.histogram(v.name, v)\n",
    "\n",
    "        tf.summary.scalar(\"Scalars/Total_Loss\", loss)\n",
    "        return self.optimizer.apply_gradients(grads, self.global_step)\n",
    "\n",
    "    def Stat(self, data):\n",
    "        self.writer.add_summary(\n",
    "            tf.Summary(\n",
    "                value=[tf.Summary.Value(tag=name, simple_value=value)\n",
    "                       for name, value in data.items()]), self.cur_step)\n",
    "\n",
    "    def Save(self, sess):\n",
    "        self.saver.save(sess, os.path.basename(self.run_index),\n",
    "                        global_step=self.global_step)\n",
    "        if self.last_start is not None:\n",
    "            self.writer.add_summary(\n",
    "                tf.Summary(\n",
    "                    value=[tf.Summary.Value(\n",
    "                        tag='Steps per sec',\n",
    "                        simple_value=self.options['update_steps'] / (time.time() - self.last_start))]),\n",
    "                self.cur_step)\n",
    "        self.last_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DEFAULT_OPTIONS = {\n",
    "    'clip_grad': 3.,\n",
    "    'learning_rate': 0.001,\n",
    "    'update_steps': 10000,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class QLearner(BaseLearner):\n",
    "    def __init__(self, exp_buffer, state2q, options=DEFAULT_OPTIONS):\n",
    "        super(QLearner, self).__init__(options)\n",
    "\n",
    "        self.exp_buffer = exp_buffer\n",
    "\n",
    "        self.state = tf.placeholder(tf.float32, shape=[None, self.exp_buffer.state_size],\n",
    "                                    name='state')\n",
    "        self.action = tf.placeholder(tf.int32, shape=[None], name='action')\n",
    "        self.reward = tf.placeholder(tf.float32, shape=[None], name='reward')\n",
    "        self.state1 = tf.placeholder(tf.float32, shape=[None, self.exp_buffer.state_size],\n",
    "                                     name='state1')\n",
    "        self.gamma = tf.placeholder(tf.float32, shape=[None], name='gamma')\n",
    "        self.is_weights = tf.placeholder(tf.float32, shape=[None], name='is_weights')\n",
    "        self.is_training = tf.placeholder(tf.bool, shape=None, name='is_training')\n",
    "\n",
    "        with tf.variable_scope('model', reuse=False):\n",
    "            self.qvalues = state2q(self.state, self.is_training)\n",
    "        with tf.variable_scope('model', reuse=True):\n",
    "            self.qvalues1 = state2q(self.state1, self.is_training)\n",
    "        with tf.variable_scope('target', reuse=False):\n",
    "            self.qvalues_target = state2q(self.state1, self.is_training)\n",
    "\n",
    "        self.vars_pred = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, 'model')\n",
    "        self.vars_target = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, 'target')\n",
    "\n",
    "        self.copy_op = tf.group(\n",
    "            *[tf.assign(y, x) for x, y in zip(self.vars_pred, self.vars_target)]\n",
    "        )\n",
    "\n",
    "        self.act_s1 = tf.cast(tf.argmax(self.qvalues1, dimension=1), tf.int32)\n",
    "        self.q_s1 = Select(self.qvalues_target, self.act_s1)\n",
    "        self.target_q = tf.stop_gradient(self.reward + self.gamma * self.q_s1)\n",
    "        self.q = Select(self.qvalues, self.action)\n",
    "#         self.q = Select4(self.qvalues, self.action)\n",
    "\n",
    "        self.delta = self.target_q - self.q\n",
    "        self.td_err_weight = tf.abs(self.delta)\n",
    "        self.loss = tf.reduce_mean(HuberLoss(self.delta, 5) * self.is_weights)\n",
    "\n",
    "        self.train_op = self.Optimize(self.loss)\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        self.train_op = tf.group(self.train_op, *update_ops)\n",
    "\n",
    "        tf.summary.histogram('Monitor/TD_Error', self.delta)\n",
    "        tf.summary.histogram('Monitor/Q', self.q)\n",
    "        tf.summary.histogram('Monitor/Weights', self.is_weights)\n",
    "        tf.summary.scalar(\"Scalars/Q\", tf.reduce_mean(self.q))\n",
    "        tf.summary.scalar('Scalars/Weights', tf.reduce_mean(self.is_weights))\n",
    "\n",
    "        self.summary_op = tf.summary.merge_all()\n",
    "        self.saver = None\n",
    "\n",
    "    def Vars(self):\n",
    "        return tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'model')\n",
    "\n",
    "    def Step(self, sess, batch_size=32):\n",
    "        idx, ss, aa, rr, ss1, gg, ww = self.exp_buffer.sample(batch_size)\n",
    "        if ss is None:\n",
    "            return\n",
    "\n",
    "        feed_dict = {self.state: ss, self.action: aa, self.reward: rr, self.state1:ss1,\n",
    "                     self.gamma: gg, self.is_weights: ww,\n",
    "                     self.is_training: True}\n",
    "\n",
    "        if self.cur_step and self.cur_step % 100 != 0:\n",
    "            self.cur_step, weights, _ = sess.run(\n",
    "                [self.global_step, self.td_err_weight, self.train_op], feed_dict)\n",
    "        else:\n",
    "            self.cur_step, weights, _, smr = sess.run(\n",
    "                [self.global_step, self.td_err_weight, self.train_op, self.summary_op], feed_dict)\n",
    "            self.writer.add_summary(smr, self.cur_step)\n",
    "\n",
    "        for ii, td_w in zip(idx, weights):\n",
    "            self.exp_buffer.tree_update(ii, td_w)\n",
    "\n",
    "        if self.cur_step % self.options['update_steps'] == 0:\n",
    "            print 'Updated target network'\n",
    "            sess.run(self.copy_op)\n",
    "            self.Save(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-02-25 23:05:30,487] Making new env: Pong-v0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Pong-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import atari_wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def EnvFactory(env_name):\n",
    "    parts = env_name.split(':')\n",
    "    if len(parts) > 2:\n",
    "        raise ValueError('Incorrect environment name %s' % env_name)\n",
    "\n",
    "    env = gym.make(parts[0])\n",
    "    if len(parts) == 2:\n",
    "        for letter in parts[1]:\n",
    "            if letter == 'L':\n",
    "                env = atari_wrappers.EpisodicLifeEnv(env)\n",
    "            elif letter == 'N':\n",
    "                env = atari_wrappers.NoopResetEnv(env, noop_max=30)\n",
    "            elif letter == 'S':\n",
    "                env = atari_wrappers.MaxAndSkipEnv(env, skip=4)\n",
    "            elif letter == 'F':\n",
    "                env = atari_wrappers.FireResetEnv(env)\n",
    "            elif letter == 'C':\n",
    "                env = atari_wrappers.ClippedRewardsWrapper(env)\n",
    "            elif letter == 'P':\n",
    "                env = atari_wrappers.ProcessFrame84(env)\n",
    "            else:\n",
    "                raise ValueError('Unexpected code of wrapper %s' % letter)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-02-25 23:32:04,734] Making new env: Pong-v0\n"
     ]
    }
   ],
   "source": [
    "env = EnvFactory('Pong-v0:LNSFCP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 84, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(84, 84, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = env.render(mode='rgb_array')\n",
    "env.render(close=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'EncodePng:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.image.encode_png(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CartPoleQNetwork(state, unused_is_training):\n",
    "    hidden = tf.contrib.layers.fully_connected(\n",
    "        state, 32,\n",
    "        activation_fn=tf.nn.elu,\n",
    "        weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "        scope='hidden1')\n",
    "    hidden = tf.contrib.layers.fully_connected(\n",
    "        hidden, 32,\n",
    "        activation_fn=tf.nn.elu,\n",
    "        weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "        scope='hidden2')\n",
    "\n",
    "    value = tf.contrib.layers.linear(hidden, 1,\n",
    "                                     weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "                                     biases_initializer=tf.constant_initializer(0.),\n",
    "                                     scope='value')\n",
    "    adv = tf.contrib.layers.linear(hidden, env.action_space.n,  # num_actions\n",
    "                                   weights_initializer=tf.truncated_normal_initializer(stddev=0.01),\n",
    "                                   scope='advantage')\n",
    "    adv = tf.subtract(adv, tf.reduce_mean(adv, reduction_indices=1, keep_dims=True), 'advantage')\n",
    "\n",
    "    output = tf.add(value, adv, 'output')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ROLLOUT_LEN = 20\n",
    "GAMMA = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buf = WeightedExperienceBuffer(0.6, 0.4, 100, 1 << 15)\n",
    "old_s = env.reset()\n",
    "for _ in range(50):\n",
    "    ss, aa, rr, ss1, gg = [], [], [], [], []\n",
    "    done = False\n",
    "    while not done and len(ss) < ROLLOUT_LEN:\n",
    "        a = env.action_space.sample()\n",
    "    \n",
    "        s, r, done, _ = env.step(a)\n",
    "        ss.append(old_s)\n",
    "        aa.append(a)\n",
    "        rr.append(r)\n",
    "        ss1.append(s)\n",
    "        gg.append(GAMMA if not done else 0.)\n",
    "\n",
    "        old_s = s\n",
    "    \n",
    "    rew = 0.\n",
    "    g = 1.\n",
    "    for i in reversed(range(len(ss))):\n",
    "        rew = rr[i] + gg[i] * rew\n",
    "        g *= gg[i]\n",
    "        ss1[i] = old_s\n",
    "        rr[i] = r\n",
    "        gg[i] = g\n",
    "    \n",
    "    if done:\n",
    "        old_s = env.reset()\n",
    "    \n",
    "    buf.add(np.array(ss), np.array(aa), np.array(rr), np.array(ss1), np.array(gg), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Select(value, index):\n",
    "    # Value - float tensor of (batch, actions) size\n",
    "    # index - int32 tensor of (batch) size\n",
    "    # returns float tensor of batch size where in every batch the element from index is selected\n",
    "    batch_size = tf.shape(value)[0]\n",
    "    _range = tf.range(0, batch_size)\n",
    "    ind = tf.concat([tf.expand_dims(_range, 1), \n",
    "                     tf.expand_dims(index, 1)], 1)\n",
    "    return tf.gather_nd(value, ind)\n",
    "\n",
    "\n",
    "def Select4(value, index):\n",
    "    # Value - float tensor of (batch, actions) size\n",
    "    # index - int32 tensor of (batch) size\n",
    "    # returns float tensor of batch size where in every batch the element from index is selected\n",
    "    shp = tf.shape(value)\n",
    "    return tf.reduce_sum(value * tf.one_hot(index, shp[1]), reduction_indices=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sess.close()\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name model/hidden1/weights:0/grad is illegal; using model/hidden1/weights_0/grad instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-02-19 23:41:14,555] Summary name model/hidden1/weights:0/grad is illegal; using model/hidden1/weights_0/grad instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name model/hidden1/weights:0 is illegal; using model/hidden1/weights_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-02-19 23:41:14,559] Summary name model/hidden1/weights:0 is illegal; using model/hidden1/weights_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name model/hidden1/biases:0/grad is illegal; using model/hidden1/biases_0/grad instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-02-19 23:41:14,562] Summary name model/hidden1/biases:0/grad is illegal; using model/hidden1/biases_0/grad instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name model/hidden1/biases:0 is illegal; using model/hidden1/biases_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-02-19 23:41:14,565] Summary name model/hidden1/biases:0 is illegal; using model/hidden1/biases_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name model/hidden2/weights:0/grad is illegal; using model/hidden2/weights_0/grad instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-02-19 23:41:14,568] Summary name model/hidden2/weights:0/grad is illegal; using model/hidden2/weights_0/grad instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name model/hidden2/weights:0 is illegal; using model/hidden2/weights_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-02-19 23:41:14,572] Summary name model/hidden2/weights:0 is illegal; using model/hidden2/weights_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name model/hidden2/biases:0/grad is illegal; using model/hidden2/biases_0/grad instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-02-19 23:41:14,576] Summary name model/hidden2/biases:0/grad is illegal; using model/hidden2/biases_0/grad instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name model/hidden2/biases:0 is illegal; using model/hidden2/biases_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-02-19 23:41:14,581] Summary name model/hidden2/biases:0 is illegal; using model/hidden2/biases_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name model/value/weights:0/grad is illegal; using model/value/weights_0/grad instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-02-19 23:41:14,586] Summary name model/value/weights:0/grad is illegal; using model/value/weights_0/grad instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name model/value/weights:0 is illegal; using model/value/weights_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-02-19 23:41:14,590] Summary name model/value/weights:0 is illegal; using model/value/weights_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name model/value/biases:0/grad is illegal; using model/value/biases_0/grad instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-02-19 23:41:14,595] Summary name model/value/biases:0/grad is illegal; using model/value/biases_0/grad instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name model/value/biases:0 is illegal; using model/value/biases_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-02-19 23:41:14,598] Summary name model/value/biases:0 is illegal; using model/value/biases_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name model/advantage/weights:0/grad is illegal; using model/advantage/weights_0/grad instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-02-19 23:41:14,602] Summary name model/advantage/weights:0/grad is illegal; using model/advantage/weights_0/grad instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name model/advantage/weights:0 is illegal; using model/advantage/weights_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-02-19 23:41:14,607] Summary name model/advantage/weights:0 is illegal; using model/advantage/weights_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name model/advantage/biases:0/grad is illegal; using model/advantage/biases_0/grad instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-02-19 23:41:14,610] Summary name model/advantage/biases:0/grad is illegal; using model/advantage/biases_0/grad instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name model/advantage/biases:0 is illegal; using model/advantage/biases_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-02-19 23:41:14,614] Summary name model/advantage/biases:0 is illegal; using model/advantage/biases_0 instead.\n"
     ]
    }
   ],
   "source": [
    "ql = QLearner(buf, CartPoleQNetwork, options={\n",
    "    'clip_grad': 3.,\n",
    "    'learning_rate': 0.0001,\n",
    "    'update_steps': 15000,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ql.Init(sess, 'practice/lander-ql-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated target network\n",
      "Updated target network\n",
      "Updated target network\n",
      "Updated target network\n",
      "Updated target network\n",
      "Updated target network\n",
      "Updated target network\n",
      "Updated target network\n",
      "Updated target network\n",
      "Updated target network\n",
      "Updated target network\n",
      "Updated target network\n",
      "Updated target network\n",
      "Updated target network\n",
      "Updated target network\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-6cd00f14e1a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-63f86d27e544>\u001b[0m in \u001b[0;36mStep\u001b[0;34m(self, sess, batch_size)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtd_w\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtd_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcur_step\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'update_steps'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-e80950f5995c>\u001b[0m in \u001b[0;36mtree_update\u001b[0;34m(self, buffer_index, new_weight)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtree_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_in_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mnew_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_weight\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_weight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_sums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "episode_rew = 0.\n",
    "episode_len = 0.\n",
    "old_s = env.reset()\n",
    "for i in range(100500100):\n",
    "    ss, aa, rr, ss1, gg = [], [], [], [], []\n",
    "    done = False\n",
    "    if i % 5 == 0:\n",
    "        while not done and len(ss) < ROLLOUT_LEN:\n",
    "            epsilon = 0.3 / (1 + (ql.cur_step or 0.) / 500000.)\n",
    "            if np.random.sample() < epsilon:\n",
    "                a = env.action_space.sample()\n",
    "            else:\n",
    "                a = sess.run(ql.act_s1, {ql.state1: np.reshape(old_s, (1, -1)),\n",
    "                                         ql.is_training: False})\n",
    "                a = a[0]\n",
    "\n",
    "            s, r, done, _ = env.step(a)\n",
    "\n",
    "            ss.append(old_s)\n",
    "            aa.append(a)\n",
    "            rr.append(r)\n",
    "            ss1.append(s)\n",
    "            gg.append(GAMMA if not done else 0.0)\n",
    "\n",
    "            episode_rew += r\n",
    "            episode_len += 1\n",
    "\n",
    "            old_s = s\n",
    "\n",
    "        rew = 0.\n",
    "        g = 1.\n",
    "        for i in reversed(range(len(ss))):\n",
    "            rew = rr[i] + gg[i] * rew\n",
    "            g *= gg[i]\n",
    "            ss1[i] = old_s\n",
    "            rr[i] = r\n",
    "            gg[i] = g\n",
    "\n",
    "        if done:\n",
    "            ql.Stat({'Env/Reward': episode_rew, 'Env/Length': episode_len})\n",
    "            episode_rew, episode_len = 0., 0.\n",
    "            old_s = env.reset()\n",
    "\n",
    "        buf.add(np.array(ss), np.array(aa), np.array(rr), np.array(ss1), np.array(gg), 100)\n",
    "\n",
    "    ql.Step(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 (TF Source)",
   "language": "python",
   "name": "tf_source"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
